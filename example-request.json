{
  "input": {
    "workflow": {
      "37": {
        "inputs": {
          "filename": "qwen/qwen_image_edit_fp8_e4m3fn.safetensors"
        },
        "class_type": "UNETLoader",
        "_meta": {
          "title": "UNETLoader"
        }
      },
      "110": {
        "inputs": {
          "value": 1,
          "model": [
            "125",
            0
          ]
        },
        "class_type": "CFGNorm",
        "_meta": {
          "title": "CFGNorm"
        }
      },
      "111": {
        "inputs": {
          "filename": "qwen_image_vae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "VAELoader"
        }
      },
      "112": {
        "inputs": {
          "filename": "qwen_2.5_vl_7b_fp8_scaled.safetensors"
        },
        "class_type": "CLIPLoader",
        "_meta": {
          "title": "CLIPLoader"
        }
      },
      "113": {
        "inputs": {
          "pixels": [
            "115",
            0
          ],
          "vae": [
            "111",
            0
          ]
        },
        "class_type": "VAEEncode",
        "_meta": {
          "title": "VAEEncode"
        }
      },
      "114": {
        "inputs": {
          "text": "",
          "clip": [
            "112",
            0
          ],
          "vae": [
            "111",
            0
          ],
          "image": [
            "115",
            0
          ]
        },
        "class_type": "TextEncodeQwenImageEdit",
        "_meta": {
          "title": "Negative Prompt"
        }
      },
      "115": {
        "inputs": {
          "text": "lanczos",
          "image": [
            "196",
            0
          ]
        },
        "class_type": "ImageScaleToTotalPixels",
        "_meta": {
          "title": "ImageScaleToTotalPixels"
        }
      },
      "116": {
        "inputs": {
          "filename_prefix": "VTon",
          "images": [
            "119",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "SaveImage"
        }
      },
      "119": {
        "inputs": {
          "samples": [
            "122",
            0
          ],
          "vae": [
            "111",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAEDecode"
        }
      },
      "121": {
        "inputs": {
          "text": "Style the person in the top of the image, with every article of clothing on the bottom, \n\n",
          "clip": [
            "112",
            0
          ],
          "vae": [
            "111",
            0
          ],
          "image": [
            "196",
            0
          ]
        },
        "class_type": "TextEncodeQwenImageEdit",
        "_meta": {
          "title": "Prompt"
        }
      },
      "122": {
        "inputs": {
          "seed": 572,
          "steps": 30,
          "cfg": 2.5,
          "sampler_name": "euler",
          "scheduler": "simple",
          "denoise": 1,
          "model": [
            "110",
            0
          ],
          "positive": [
            "121",
            0
          ],
          "negative": [
            "114",
            0
          ],
          "latent_image": [
            "113",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "125": {
        "inputs": {
          "value": 3,
          "model": [
            "233",
            0
          ]
        },
        "class_type": "ModelSamplingAuraFlow",
        "_meta": {
          "title": "ModelSamplingAuraFlow"
        }
      },
      "170": {
        "inputs": {
          "image": "Runcomfy_Example_ (4).png"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "Person"
        }
      },
      "175": {
        "inputs": {
          "image": "Runcomfy_Example_ (2).png"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "LoadImage"
        }
      },
      "177": {
        "inputs": {
          "image": "Runcomfy_Example_ (1).png"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "LoadImage"
        }
      },
      "179": {
        "inputs": {
          "image": "Runcomfy_Example_ (3).png"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "LoadImage"
        }
      },
      "196": {
        "inputs": {
          "value": 832,
          "image": [
            "284",
            0
          ]
        },
        "class_type": "ImageResizeKJv2",
        "_meta": {
          "title": "Qwen friendly res"
        }
      },
      "233": {
        "inputs": {
          "filename": "qwen/Try_On_Qwen_Edit_Lora.safetensors",
          "model": [
            "37",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      },
      "240": {
        "inputs": {
          "images": [
            "196",
            0
          ]
        },
        "class_type": "PreviewImage",
        "_meta": {
          "title": "PreviewImage"
        }
      },
      "250": {
        "inputs": {
          "text": "right",
          "image1": [
            "196",
            0
          ],
          "image2": [
            "119",
            0
          ]
        },
        "class_type": "ImageStitch",
        "_meta": {
          "title": "ImageStitch"
        }
      },
      "251": {
        "inputs": {
          "filename_prefix": "Compare",
          "images": [
            "250",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "SaveImage"
        }
      },
      "280": {
        "inputs": {
          "text": "right",
          "image1": [
            "175",
            0
          ],
          "image2": [
            "177",
            0
          ]
        },
        "class_type": "ImageStitch",
        "_meta": {
          "title": "ImageStitch"
        }
      },
      "282": {
        "inputs": {
          "text": "right",
          "image1": [
            "280",
            0
          ],
          "image2": [
            "179",
            0
          ]
        },
        "class_type": "ImageStitch",
        "_meta": {
          "title": "ImageStitch"
        }
      },
      "284": {
        "inputs": {
          "text": "down",
          "image1": [
            "170",
            0
          ],
          "image2": [
            "282",
            0
          ]
        },
        "class_type": "ImageStitch",
        "_meta": {
          "title": "ImageStitch"
        }
      }
    }
  }
}